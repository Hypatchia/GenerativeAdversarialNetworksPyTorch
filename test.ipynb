{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define generator function\n",
    "def generator(input_dim ,output_dim):\n",
    "\n",
    "    '''\n",
    "    Function to return a neural network representing the generator \n",
    "    Parameters :\n",
    "        input_dim : dimension of input vector\n",
    "        output_dim : dimension of output vector\n",
    "    \n",
    "    Returns :\n",
    "        Generator Model having a set of layers.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    return nn.Sequential(\n",
    "        # Linear Transformation Layer\n",
    "        # y = xA' + b\n",
    "        nn.Linear(input_dim,output_dim),\n",
    "        # BatchNormalization\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        # Activation Layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator test Function \n",
    "def test_generator(in_dim,out_dim,test_size):\n",
    "    \"\"\" \n",
    "    Function for testing the Generator \n",
    "    Parameters :\n",
    "        in_dim : input vector dimension\n",
    "        out_dim : output vector dimension\n",
    "        test_size : number of obseravtions to test on\n",
    "\n",
    "    Returns :\n",
    "        set of assertions completed successfully\n",
    "    \"\"\"\n",
    "    # Verify the generator block function\n",
    "    #in_dim = 45\n",
    "    #out_dim = 17\n",
    "    #test_size =2000\n",
    "    \n",
    "    Gen = generator(in_dim,out_dim)\n",
    "    assert len(Gen)==3\n",
    "    assert type(Gen[0])==nn.Linear\n",
    "    assert type(Gen[1])==nn.BatchNorm1d\n",
    "    assert type(Gen[2])==nn.ReLU\n",
    "\n",
    "    # Verify Input Output\n",
    "    test_inpt = torch.randn(test_size,in_dim)\n",
    "    test_outp = Gen(test_inpt)\n",
    "    assert tuple(test_outp.shape)==(test_size, out_dim)\n",
    "    assert test_outp.std() > 0.55\n",
    "    assert test_outp.std() <0.65\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Generator\n",
    "test_generator(25,12,2000)\n",
    "test_generator(75,12,200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Generator Class \n",
    "\n",
    "class Generator(nn.Module) :\n",
    "    \"\"\" \n",
    "    Generator Class\n",
    "    Values :\n",
    "    z_dim : dimension of noise vector \n",
    "    im_dim : dimension of images\n",
    "            MNIST images are of dim 28 x 28 = 784\n",
    "    hidden_im : inner dimension \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim = 10 ,im_dim = 784,hidden_dim = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            Generator(z_dim,hidden_dim),\n",
    "            Generator(hidden_dim,hidden_dim * 2),\n",
    "            Generator(hidden_dim * 2,hidden_dim * 4),\n",
    "            Generator(hidden_dim * 4,hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, im_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function to complete a forward pass of the generator: \n",
    "        Given a noise tensor, returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return self.gen(noise)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define noise function\n",
    "def get_noise(n_samples, z_dim, device ='cpu'):\n",
    "    ''' \n",
    "    Function for generating random noise vector given sample size\n",
    "    and dimension of noise vector \n",
    "    Parameters :\n",
    "        n_samples : number of noise samples to generate\n",
    "        z_dim : dim of noise vector , number of values in each sample \n",
    "        device : type of device : cuda, cpu ...\n",
    "    \n",
    "    '''\n",
    "\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test for noise function\n",
    "def test_noise(n_samples,z_dim,device='cpu'):\n",
    "    noise = get_noise(n_samples , z_dim,device)\n",
    "\n",
    "\n",
    "    assert tuple(noise.shape) == (n_samples , z_dim)\n",
    "    assert torch.abs(noise.std() - torch.tensor(1.0)) < 0.01\n",
    "    assert str(noise.device).startswith(device)\n",
    "\n",
    "    print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "test_noise(1000,100,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define descriminator function\n",
    "\n",
    "def Discriminator(input_dim, output_dim):\n",
    "    \"\"\" \n",
    "    Disciminator Function\n",
    "    Function returns Discriminator Layers\n",
    "    Params :\n",
    "        input_dim : dimension of input vector\n",
    "        output_dim : dimension of output vector\n",
    "\n",
    "    Returns :\n",
    "        Discriminator Neural Net\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim,output_dim),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Discriminator Class\n",
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "            (MNIST images are 28x28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            discriminator(im_dim, hidden_dim * 4),\n",
    "            discriminator(hidden_dim * 4, hidden_dim * 2),\n",
    "            discriminator(hidden_dim * 2, hidden_dim),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "           \n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\" \n",
    "        Function to make a forward pass for discriminator\n",
    "        Given fake images , return whether it's fake or real\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.disc(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "\n",
    "# Load MNIST dataset as tensors\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# Pick cpu as device\n",
    "device = 'cpu'\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Inititialize \n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for discriminator loss\n",
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the discriminator given inputs.\n",
    "    Parameters:\n",
    "        gen: generator model, returns an image given z-dimensional noise\n",
    "        disc: discriminator model, returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function,\n",
    "        real: a batch of real images\n",
    "        num_images: the number of images the generator should produce, \n",
    "               also the length of the real images\n",
    "        z_dim: dimension of the noise vector, a scalar\n",
    "        device: device type\n",
    "    Returns:\n",
    "        disc_loss: \n",
    "    '''\n",
    " \n",
    "    noise = get_noise(num_images , z_dim,device=device)\n",
    "    fakes = gen(noise).detach()\n",
    "    fake_prediction = disc(fakes)\n",
    "    fake_loss = criterion(fake_prediction, torch.zeros_like(fake_prediction))\n",
    "    real_prediction = disc(real)\n",
    "    real_loss = criterion(real_prediction, torch.ones_like(real_prediction))\n",
    "    disc_loss = (fake_loss + real_loss)/2\n",
    "   \n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for generator loss\n",
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return \n",
    "    Parameters:\n",
    "        gen: \n",
    "        disc: \n",
    "        criterion: \n",
    "        num_images: \n",
    "        z_dim: \n",
    "        device: \n",
    "    Returns:\n",
    "        gen_loss:\n",
    "    '''\n",
    "    noise = get_noise(num_images , z_dim,device)\n",
    "    fakes = gen(noise)\n",
    "    fake_prediction = disc(fakes)\n",
    "    gen_loss = criterion(fake_prediction, torch.ones_like(fake_prediction))\n",
    "   \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7017eaa3a1146aa3353aaf1d457acd0d42a48245368b654c92322235b5e5999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
